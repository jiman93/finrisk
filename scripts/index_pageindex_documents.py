#!/usr/bin/env python3
"""
Submit locally downloaded 10-K PDFs to PageIndex and produce ticker->doc_id mapping.

Usage:
  python scripts/index_pageindex_documents.py --tickers MSFT
  python scripts/index_pageindex_documents.py --tickers MSFT AAPL TSLA
"""

from __future__ import annotations

import argparse
import json
import os
import sys
import time
from dataclasses import dataclass, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import httpx


DEFAULT_INPUT_MANIFEST = "data/metadata/edgar_10k_manifest.json"
DEFAULT_OUTPUT_MANIFEST = "data/metadata/pageindex_index_manifest.json"
DEFAULT_OUTPUT_DOC_MAP = "data/metadata/pageindex_doc_map.env"


@dataclass
class PageIndexRecord:
    ticker: str
    pdf_path: str
    doc_id: str
    status: str
    retrieval_ready: bool
    submitted_at: str
    completed_at: str | None
    last_checked_at: str
    error: str | None


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Submit filing PDFs to PageIndex and poll until retrieval-ready."
    )
    parser.add_argument(
        "--input-manifest",
        default=DEFAULT_INPUT_MANIFEST,
        help="Input EDGAR manifest generated by download_10k_html.py",
    )
    parser.add_argument(
        "--output-manifest",
        default=DEFAULT_OUTPUT_MANIFEST,
        help="Output manifest containing PageIndex doc IDs and status.",
    )
    parser.add_argument(
        "--output-doc-map",
        default=DEFAULT_OUTPUT_DOC_MAP,
        help="Output env snippet containing PAGEINDEX_DOC_MAP mapping.",
    )
    parser.add_argument(
        "--tickers",
        nargs="*",
        default=[],
        help="Optional tickers to process. Default: all from input manifest.",
    )
    parser.add_argument(
        "--api-key",
        default=os.getenv("PAGEINDEX_API_KEY", "").strip(),
        help="PageIndex API key. Defaults to PAGEINDEX_API_KEY env var.",
    )
    parser.add_argument(
        "--base-url",
        default=os.getenv("PAGEINDEX_BASE_URL", "https://api.pageindex.ai").strip(),
        help="PageIndex base URL (default: https://api.pageindex.ai)",
    )
    parser.add_argument(
        "--poll-interval-seconds",
        type=float,
        default=4.0,
        help="Poll interval after submission (default: 4 seconds).",
    )
    parser.add_argument(
        "--poll-timeout-seconds",
        type=int,
        default=1200,
        help="Per-document poll timeout in seconds (default: 1200).",
    )
    parser.add_argument(
        "--force-reindex",
        action="store_true",
        help="Re-submit ticker even if already marked retrieval-ready in output manifest.",
    )
    return parser.parse_args()


def utc_now() -> str:
    return datetime.now(timezone.utc).isoformat()


def require_api_key(api_key: str) -> str:
    if api_key:
        return api_key
    raise ValueError("Missing PageIndex API key. Set PAGEINDEX_API_KEY or pass --api-key.")


def load_json(path: Path) -> dict[str, Any]:
    if not path.exists():
        return {}
    return json.loads(path.read_text(encoding="utf-8"))


def load_input_records(path: Path) -> list[dict[str, Any]]:
    payload = load_json(path)
    records = payload.get("records", [])
    if not records:
        raise ValueError(f"No records found in input manifest: {path}")
    return records


def load_output_records(path: Path) -> dict[str, PageIndexRecord]:
    payload = load_json(path)
    records = payload.get("records", [])
    out: dict[str, PageIndexRecord] = {}
    for row in records:
        try:
            rec = PageIndexRecord(**row)
            out[rec.ticker] = rec
        except TypeError:
            continue
    return out


def save_output_manifest(path: Path, records: dict[str, PageIndexRecord]) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    payload = {
        "generated_at": utc_now(),
        "records": [asdict(records[ticker]) for ticker in sorted(records.keys())],
    }
    path.write_text(json.dumps(payload, indent=2), encoding="utf-8")


def save_doc_map(path: Path, records: dict[str, PageIndexRecord]) -> None:
    ready = [r for r in records.values() if r.retrieval_ready and r.doc_id]
    ready = sorted(ready, key=lambda r: r.ticker)
    mapping = ",".join([f"{r.ticker}:{r.doc_id}" for r in ready])

    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(f"PAGEINDEX_DOC_MAP={mapping}\n", encoding="utf-8")


def submit_document(client: httpx.Client, base_url: str, api_key: str, pdf_path: Path) -> str:
    with pdf_path.open("rb") as file_obj:
        files = {"file": (pdf_path.name, file_obj, "application/pdf")}
        response = client.post(
            f"{base_url.rstrip('/')}/doc/",
            headers={"api_key": api_key},
            files=files,
        )
    if response.status_code >= 400:
        detail = ""
        try:
            detail = str(response.json().get("detail", "")).strip()
        except Exception:
            detail = response.text.strip()
        if detail:
            raise RuntimeError(f"PageIndex submit failed ({response.status_code}): {detail}")
        raise RuntimeError(f"PageIndex submit failed ({response.status_code})")
    data = response.json()
    doc_id = data.get("doc_id")
    if not doc_id:
        raise RuntimeError(f"PageIndex response missing doc_id: {data}")
    return str(doc_id)


def poll_until_ready(
    client: httpx.Client,
    base_url: str,
    api_key: str,
    doc_id: str,
    poll_interval_seconds: float,
    poll_timeout_seconds: int,
) -> tuple[str, bool]:
    deadline = time.time() + poll_timeout_seconds
    status = "unknown"
    retrieval_ready = False
    url = f"{base_url.rstrip('/')}/doc/{doc_id}/"

    while time.time() < deadline:
        response = client.get(url, headers={"api_key": api_key}, params={"type": "tree"})
        if response.status_code >= 400:
            detail = ""
            try:
                detail = str(response.json().get("detail", "")).strip()
            except Exception:
                detail = response.text.strip()
            if detail:
                raise RuntimeError(f"PageIndex poll failed ({response.status_code}): {detail}")
            raise RuntimeError(f"PageIndex poll failed ({response.status_code})")
        data = response.json()

        status = str(data.get("status", status))
        retrieval_ready = bool(data.get("retrieval_ready", False))
        if status == "completed" and retrieval_ready:
            return status, retrieval_ready
        if status in {"failed", "error"}:
            return status, retrieval_ready
        time.sleep(poll_interval_seconds)

    return status, retrieval_ready


def main() -> int:
    args = parse_args()
    api_key = require_api_key(args.api_key)

    input_manifest_path = Path(args.input_manifest)
    output_manifest_path = Path(args.output_manifest)
    output_doc_map_path = Path(args.output_doc_map)

    input_records = load_input_records(input_manifest_path)
    existing_records = load_output_records(output_manifest_path)

    requested_tickers = {ticker.upper() for ticker in args.tickers} if args.tickers else set()
    candidates: list[dict[str, Any]] = []
    for row in input_records:
        ticker = str(row.get("ticker", "")).upper()
        if not ticker:
            continue
        if requested_tickers and ticker not in requested_tickers:
            continue
        candidates.append(row)

    if not candidates:
        raise ValueError("No matching input records to process.")

    print(f"Submitting {len(candidates)} document(s) to PageIndex...")
    failures = 0

    with httpx.Client(timeout=60) as client:
        for row in candidates:
            ticker = str(row["ticker"]).upper()
            pdf_path = Path(str(row.get("pdf_path", "")))
            if not pdf_path.exists():
                print(f"[FAIL] {ticker}: PDF not found at {pdf_path}")
                failures += 1
                continue

            current = existing_records.get(ticker)
            if (
                current
                and current.retrieval_ready
                and current.doc_id
                and not args.force_reindex
            ):
                print(f"[SKIP] {ticker}: already retrieval-ready ({current.doc_id})")
                continue

            should_reuse_existing_doc = (
                current
                and current.doc_id
                and not args.force_reindex
                and not current.retrieval_ready
            )

            submitted_at = utc_now()
            try:
                if should_reuse_existing_doc:
                    doc_id = current.doc_id
                    submitted_at = current.submitted_at
                    print(f"[POLL] {ticker}: reusing existing doc_id {doc_id}")
                else:
                    doc_id = submit_document(client, args.base_url, api_key, pdf_path)
                    print(f"[SUBMIT] {ticker}: {doc_id}")

                status, retrieval_ready = poll_until_ready(
                    client=client,
                    base_url=args.base_url,
                    api_key=api_key,
                    doc_id=doc_id,
                    poll_interval_seconds=args.poll_interval_seconds,
                    poll_timeout_seconds=args.poll_timeout_seconds,
                )

                completed_at = utc_now() if (status == "completed" and retrieval_ready) else None
                rec = PageIndexRecord(
                    ticker=ticker,
                    pdf_path=str(pdf_path),
                    doc_id=doc_id,
                    status=status,
                    retrieval_ready=retrieval_ready,
                    submitted_at=submitted_at,
                    completed_at=completed_at,
                    last_checked_at=utc_now(),
                    error=None if retrieval_ready else f"status={status}, retrieval_ready={retrieval_ready}",
                )
                existing_records[ticker] = rec

                if retrieval_ready:
                    print(f"[OK] {ticker}: ready ({doc_id})")
                else:
                    print(f"[WAIT] {ticker}: not ready yet ({doc_id}) status={status}")
            except Exception as exc:
                failures += 1
                error_text = str(exc)
                print(f"[FAIL] {ticker}: {error_text}")
                existing_records[ticker] = PageIndexRecord(
                    ticker=ticker,
                    pdf_path=str(pdf_path),
                    doc_id=current.doc_id if current else "",
                    status="error",
                    retrieval_ready=False,
                    submitted_at=submitted_at,
                    completed_at=None,
                    last_checked_at=utc_now(),
                    error=error_text,
                )

            save_output_manifest(output_manifest_path, existing_records)
            save_doc_map(output_doc_map_path, existing_records)

    save_output_manifest(output_manifest_path, existing_records)
    save_doc_map(output_doc_map_path, existing_records)
    ready_count = len([r for r in existing_records.values() if r.retrieval_ready and r.doc_id])
    print(f"\nSaved: {output_manifest_path}")
    print(f"Saved: {output_doc_map_path}")
    print(f"Ready mappings: {ready_count}")

    return 0 if failures == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
